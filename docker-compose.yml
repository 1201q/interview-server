version: "3.8"

services:
  app:
    image: 1201q/interview:latest
    container_name: interview
    restart: always
    expose:
      - "8000"
    networks:
      - app-network
    env_file:
      - .env
    environment:
      - ML_SERVER_URL=http://ml-server:5000
      - TZ=Asia/Seoul
    platform: linux/arm64

  ml-server:
    image: 1201q/ml-server:latest
    container_name: ml-server
    restart: always
    expose:
      - "5000"
    env_file:
      - .env
    networks:
      - app-network
    environment:
      - TZ=Asia/Seoul
    platform: linux/arm64

  nginx:
    image: nginx:latest
    container_name: nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - /etc/letsencrypt:/etc/letsencrypt
      - ./nginx.conf:/etc/nginx/nginx.conf
    depends_on:
      - app
      - ml-server
    networks:
      - app-network
    environment:
      - TZ=Asia/Seoul
    platform: linux/arm64

networks:
  app-network:
    driver: bridge
