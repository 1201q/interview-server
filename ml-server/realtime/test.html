<!doctype html>
<html lang="ko">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Whisper Live STT Demo</title>
    <style>
      body {
        font-family: sans-serif;
        padding: 2rem;
        background-color: #f7f7f7;
      }
      #out {
        border: 1px solid #ccc;
        padding: 1rem;
        min-height: 100px;
        background: white;
        margin-bottom: 1rem;
        white-space: pre-wrap;
      }
      button {
        padding: 0.5rem 1rem;
        font-size: 1rem;
      }
    </style>
  </head>
  <body>
    <h1>🎙️ Whisper 실시간 STT</h1>
    <div id="out">여기에 인식된 텍스트가 표시됩니다</div>
    <button id="startBtn">녹음 시작</button>
    <button id="stopBtn" disabled>녹음 종료</button>

    <script>
      let mediaRec, ws;
      let fullText = "";

      const startBtn = document.getElementById("startBtn");
      const stopBtn = document.getElementById("stopBtn");
      const output = document.getElementById("out");

      startBtn.onclick = async () => {
        ws = new WebSocket("ws://localhost:5000"); // WhisperLive 서버 주소
        ws.binaryType = "arraybuffer";

        ws.onopen = () => {
          console.log("WebSocket 연결됨");
        };

        ws.onmessage = (e) => {
          const { text } = JSON.parse(e.data);
          fullText += text + " ";
          output.innerText = fullText.trim();
        };

        ws.onclose = () => {
          console.log("WebSocket 종료됨");
          callGPT(fullText.trim());
        };

        const stream = await navigator.mediaDevices.getUserMedia({
          audio: true,
        });

        mediaRec = new MediaRecorder(stream, {
          mimeType: "audio/webm;codecs=opus",
        });

        mediaRec.ondataavailable = async (e) => {
          if (ws.readyState === WebSocket.OPEN) {
            const arrayBuffer = await e.data.arrayBuffer();
            ws.send(arrayBuffer);
          }
        };

        mediaRec.onstop = () => {
          if (ws.readyState === WebSocket.OPEN) {
            ws.close();
          }
        };

        mediaRec.start(3000); // 3초마다 chunk 전송
        startBtn.disabled = true;
        stopBtn.disabled = false;
      };

      stopBtn.onclick = () => {
        if (mediaRec && mediaRec.state !== "inactive") {
          mediaRec.stop();
        }
        stopBtn.disabled = true;
        startBtn.disabled = false;
      };

      async function callGPT(text) {
        if (!text || text.length < 3) {
          alert("분석할 내용이 부족합니다.");
          return;
        }

        try {
          const res = await fetch("http://localhost:8000/api/gpt", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ answer: text }),
          });

          const data = await res.json();

          if (data.result === "FOLLOW_UP") {
            alert("꼬리질문: " + data.question);
          } else {
            alert("✅ 충분한 답변입니다.");
          }
        } catch (err) {
          alert("GPT 서버 호출 실패");
          console.error(err);
        }
      }
    </script>
  </body>
</html>
